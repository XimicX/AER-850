{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1gzlqjZ08FxFVdBEbsqLwrtlOjo_JuBE3",
      "authorship_tag": "ABX9TyN0InvuY+o1Nj79k/mz4SZW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nFZPDcn0b8u1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducability\n",
        "np.random.seed(42)\n",
        "keras.utils.set_random_seed(42)"
      ],
      "metadata": {
        "id": "d-IuWmLZdO2a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input image shape\n",
        "input_shape = (500, 500, 3)\n",
        "\n",
        "# Data directories\n",
        "base_dir = '/content/drive/MyDrive/ML/Data'\n",
        "train_dir = base_dir + '/Train'\n",
        "valid_dir = base_dir + '/Valid'\n",
        "test_dir = base_dir + '/Test'"
      ],
      "metadata": {
        "id": "ZgFt9LX4dQ-W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "train_datagen = keras.Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomContrast(0.1),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomShear(0.1)\n",
        "])\n",
        "\n",
        "valid_datagen = keras.Sequential([\n",
        "    layers.Rescaling(1./255)\n",
        "])"
      ],
      "metadata": {
        "id": "V4AHK84UdSx_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "BATCH_SIZE = 32 # 16 used for model 2 due to memory limits\n",
        "train_ds_original = keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=(input_shape[0], input_shape[1]),\n",
        "    interpolation='nearest',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_ds_original = keras.utils.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=(input_shape[0], input_shape[1]),\n",
        "    interpolation='nearest',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "class_names = train_ds_original.class_names\n",
        "\n",
        "# Apply data augmentation\n",
        "train_ds = train_ds_original.map(lambda x, y: (train_datagen(x, training=True), y))\n",
        "valid_ds = valid_ds_original.map(lambda x, y: (valid_datagen(x, training=False), y))\n",
        "\n",
        "# Display number of batches\n",
        "print(f\"Number of training batches: {tf.data.experimental.cardinality(train_ds)}\")\n",
        "print(f\"Number of validation batches: {tf.data.experimental.cardinality(valid_ds)}\")"
      ],
      "metadata": {
        "id": "0qoQv_dXdfO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model1\n",
        "model1 = Sequential([\n",
        "    keras.Input(shape=input_shape),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "syoQCUZXdiq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "M1cdN7W7dk5H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "epochs = 20\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_model1 = model1.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "_QHuiRrGdopf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0209abcd"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# Save history1\n",
        "history_save_path_model1 = '/content/drive/MyDrive/ML/training_history_model1.pkl'\n",
        "\n",
        "with open(history_save_path_model1, 'wb') as f:\n",
        "    pickle.dump(history_model1.history, f)\n",
        "\n",
        "print(f\"Training history saved to: {history_save_path_model1}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model1\n",
        "model_save_path1 = '/content/drive/MyDrive/ML/trained_model1.keras'\n",
        "\n",
        "model1.save(model_save_path1)\n",
        "\n",
        "print(f\"Model saved to: {model_save_path1}\")"
      ],
      "metadata": {
        "id": "CTYJ2ob4d1L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_model1.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_model1.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_model1.history['loss'], label='Training Loss')\n",
        "plt.plot(history_model1.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gGstQSM-d_w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce62f0c4-357d-47ae-a8f4-c658b19ee324"
      },
      "source": [
        "# Model2\n",
        "model2 = Sequential([\n",
        "    keras.Input(shape=input_shape),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'), # Increased filters\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'), # Increased filters\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'), # Increased filters\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3), # Reduced dropout layer rate\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f371f8c9-4788-418a-b052-74d1705a3e91"
      },
      "source": [
        "# Compile\n",
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5), # Adjusted learning rate for stability\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0437ca09-5e17-4e47-b735-93ff02517c0a"
      },
      "source": [
        "# Training\n",
        "epochs = 20\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_model2 = model2.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1b19b51-0879-49de-8864-e39a61b012a3"
      },
      "source": [
        "# Save history2\n",
        "history_save_path_model2 = '/content/drive/MyDrive/ML/training_history_model2.pkl'\n",
        "\n",
        "with open(history_save_path_model2, 'wb') as f:\n",
        "    pickle.dump(history_model2.history, f)\n",
        "\n",
        "print(f\"Training history for model 2 saved to: {history_save_path_model2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5972246d-64ee-4c03-a432-f556265386c3"
      },
      "source": [
        "# Save model2\n",
        "model_save_path2 = '/content/drive/MyDrive/ML/trained_model2.keras'\n",
        "\n",
        "model2.save(model_save_path2)\n",
        "\n",
        "print(f\"Model 2 saved to: {model_save_path2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f54192c8"
      },
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_model2.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_model2.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model 2 Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_model2.history['loss'], label='Training Loss')\n",
        "plt.plot(history_model2.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model 2 Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc96550"
      },
      "source": [
        "# Save class names\n",
        "class_names_save_path = '/content/drive/MyDrive/ML/class_names.pkl'\n",
        "\n",
        "with open(class_names_save_path, 'wb') as f:\n",
        "    pickle.dump(class_names, f)\n",
        "\n",
        "print(f\"Class names saved to: {class_names_save_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}